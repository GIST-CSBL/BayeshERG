{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.remove('/home/hyunhokim/.local/lib/python3.6/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/hyunhokim/anaconda3/envs/BayeshERG/lib/python36.zip',\n",
       " '/home/hyunhokim/anaconda3/envs/BayeshERG/lib/python3.6',\n",
       " '/home/hyunhokim/anaconda3/envs/BayeshERG/lib/python3.6/lib-dynload',\n",
       " '',\n",
       " '/home/hyunhokim/anaconda3/envs/BayeshERG/lib/python3.6/site-packages',\n",
       " '/home/hyunhokim/anaconda3/envs/BayeshERG/lib/python3.6/site-packages/IPython/extensions',\n",
       " '/home/hyunhokim/.ipython']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/hyunhokim/anaconda3/envs/BayeshERG/lib/python3.6/site-packages/dgl/__init__.py'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dgl\n",
    "dgl.__file__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use CPU\n",
      "---------------- Target loading --------------------\n",
      "---------------- Target loading complete --------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 10/10 [00:02<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention images are saved in Folder: EX1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import dgl\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dgl.data.chem.utils import smiles_to_bigraph\n",
    "from dgl.data.chem import CanonicalAtomFeaturizer\n",
    "from dgl.data.chem import CanonicalBondFeaturizer\n",
    "from model.BayeshERG_model import BayeshERG\n",
    "from model.BayeshERG_model import RegularizationAccumulator\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from rdkit.Chem import rdmolfiles, rdmolops\n",
    "\n",
    "\n",
    "TRAIN_LEN = 14322 # Number of training data\n",
    "\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "def collate(sample):\n",
    "    graphs, labels = map(list,zip(*sample))\n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    batched_graph.set_n_initializer(dgl.init.zero_initializer)\n",
    "    batched_graph.set_e_initializer(dgl.init.zero_initializer)\n",
    "    return batched_graph, torch.tensor(labels)\n",
    "\n",
    "def load_data(df, atom_featurizer, bond_featurizer):\n",
    "    print(\"---------------- Target loading --------------------\")\n",
    "    test_g = [smiles_to_bigraph(smi, node_featurizer=atom_featurizer, edge_featurizer=bond_featurizer) for smi in df['st_smiles']]\n",
    "    test_y = [x for x in df['label']]\n",
    "    test_data = list(zip(test_g, test_y))\n",
    "    print(\"---------------- Target loading complete --------------------\")\n",
    "    return test_data\n",
    "\n",
    "def load_model(model_path):\n",
    "    wr = 1e-4 ** 2. / TRAIN_LEN\n",
    "    dr = 2. / TRAIN_LEN\n",
    "    reg_acc = RegularizationAccumulator()\n",
    "    model = BayeshERG(reg_acc=reg_acc,\n",
    "                          node_input_dim=74,\n",
    "                          edge_input_dim=12,\n",
    "                          node_hidden_dim=int(2 ** 7),\n",
    "                          edge_hidden_dim=int(2 ** 7),\n",
    "                          num_step_message_passing=7,\n",
    "                          num_step_mha=1, wr=wr, dr=dr)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model = model.to(device)\n",
    "\n",
    "    return model\n",
    "\n",
    "def prediction(model, df, test_data, device, samples = 100):\n",
    "\n",
    "    test_loader = DataLoader(test_data, batch_size=32, shuffle=False, collate_fn=collate, drop_last=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        score_df = pd.DataFrame(columns=list(range(samples)))\n",
    "        attention_result = []\n",
    "        for t in tqdm(range(samples), desc=\"Sampling\"):\n",
    "\n",
    "            true_res = []\n",
    "            pred_score = []\n",
    "            num_atom_list = []\n",
    "            pred_att = []\n",
    "\n",
    "            for _, (bg, labels) in enumerate(test_loader):\n",
    "                labels = labels.to(device)\n",
    "                lengths = bg.batch_num_nodes\n",
    "                atom_feats = bg.ndata.pop('h').to(device)\n",
    "                bond_feats = bg.edata.pop('e').to(device)\n",
    "\n",
    "                pred, w_list = model(bg, atom_feats, bond_feats)\n",
    "                w_tensor = torch.cat(w_list, dim=1)\n",
    "                w_tensor = w_tensor.detach().to('cpu').numpy()\n",
    "\n",
    "\n",
    "                pred_sof = pred[1].detach().to('cpu').numpy()\n",
    "                pred_sof = np.array(pred_sof).reshape(-1, 2)\n",
    "                pred_score.append(pred_sof)\n",
    "\n",
    "                true_label = labels.to('cpu').numpy()\n",
    "                true_res.append(true_label)\n",
    "                num_atom_list += [x + 1 for x in lengths]\n",
    "                pred_att.append(w_tensor)\n",
    "\n",
    "\n",
    "            pred_score = np.vstack(pred_score)\n",
    "            pred_att = np.hstack(pred_att)\n",
    "            attention_result.append(pred_att)\n",
    "            score_df[t] = pd.Series(pred_score[:, 1])\n",
    "\n",
    "        attention_result = np.stack(attention_result, axis=2)\n",
    "\n",
    "        class_df = score_df.mean(axis=1)\n",
    "        mean_temp = pd.concat([class_df] * (samples), axis=1, ignore_index=True)\n",
    "\n",
    "        alea_df = (score_df * (1 - score_df)).mean(axis=1)\n",
    "        epis_df = ((score_df - mean_temp) ** 2).mean(axis=1)\n",
    "        mean_att = np.mean(attention_result, axis=2)\n",
    "\n",
    "        df['score'] = class_df\n",
    "        df['alea'] = alea_df\n",
    "        df['epis'] = epis_df\n",
    "\n",
    "        return df, num_atom_list, mean_att\n",
    "\n",
    "def attention_visulaizer(name, df, mean_att, num_atom_list):\n",
    "    #os.mkdir(\"attention_results/\"+name)\n",
    "    c = 0\n",
    "    for j, n_atoms in enumerate(num_atom_list):\n",
    "        attention_coeff = mean_att[:, c:c + n_atoms]\n",
    "        mol = Chem.MolFromSmiles(df['st_smiles'].iloc[j])\n",
    "        new_order = rdmolfiles.CanonicalRankAtoms(mol)\n",
    "        mol = rdmolops.RenumberAtoms(mol, new_order)\n",
    "        for l in range(8):\n",
    "            drawer = rdMolDraw2D.MolDraw2DSVG(600, 600)\n",
    "            rdDepictor.Compute2DCoords(mol)\n",
    "            dos = drawer.drawOptions()\n",
    "            dos.atomHighlightsAreCircles = True\n",
    "            dos.fillHighlights = True\n",
    "\n",
    "            color_dict = {}\n",
    "            rad_dict = {}\n",
    "            score_dict = {}\n",
    "            bond_dict = {}\n",
    "\n",
    "            \n",
    "\n",
    "            mean_arr = 1 / len(attention_coeff[l, :])\n",
    "            \n",
    "            arr = attention_coeff[l, :][0:-1]\n",
    "            norm_arr = np.abs(((arr - np.min(arr)) / (np.max(arr)) - np.min(arr)))\n",
    "\n",
    "#            norm_arr = norm_arr\n",
    "            \n",
    "            for t, score in enumerate(norm_arr):\n",
    "                score = float(score)\n",
    "                color_dict[t] = [(1, 1 - score, 1 - score)]\n",
    "                if arr[t] > mean_arr:\n",
    "                    rad_dict[t] = 0.3\n",
    "                else: rad_dict[t] = 0\n",
    "                score_dict[t] = arr[t]\n",
    "            bonds_seq = mol.GetBonds()\n",
    "\n",
    "            for t in range(len(bonds_seq)):\n",
    "                if (score_dict[bonds_seq[t].GetBeginAtomIdx()] > mean_arr) and (score_dict[bonds_seq[t].GetEndAtomIdx()] > mean_arr):\n",
    "                    bond_dict[t] = [(0.9, 0.9, 0.9)]\n",
    "\n",
    "\n",
    "            drawer.DrawMoleculeWithHighlights(mol, '', color_dict, bond_dict, rad_dict, {})\n",
    "\n",
    "            drawer.FinishDrawing()\n",
    "            svg = drawer.GetDrawingText().replace('svg:', '')\n",
    "            with open(\"attention_results/\" + name + \"/\" + str(j) + \"_\" + str(l) + \"_\" + \".svg\", 'w') as file:\n",
    "                file.write(svg)\n",
    "                file.close()\n",
    "        c = c+n_atoms\n",
    "    print(\"Attention images are saved in Folder: \"+name)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if torch.cuda.is_available():\n",
    "        print('use GPU')\n",
    "        device = 'cuda'\n",
    "    else:\n",
    "        print('use CPU')\n",
    "        device = 'cpu'\n",
    "    warnings.warn = warn\n",
    "    \n",
    "    atom_featurizer = CanonicalAtomFeaturizer()\n",
    "    bond_featurizer = CanonicalBondFeaturizer()\n",
    "\n",
    "    data_name = 'EX1'\n",
    "    \n",
    "    df = pd.read_csv(\"Data/External/\"+data_name+\".csv\")\n",
    "    test_data = load_data(df, atom_featurizer, bond_featurizer)\n",
    "    model = load_model(\"model/model_weights.pth\")\n",
    "\n",
    "    res_df, num_atom_list, mean_att = prediction(model, df, test_data, device, samples=10)\n",
    "\n",
    "    attention_visulaizer(data_name, df, mean_att, num_atom_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19,\n",
       " 18,\n",
       " 11,\n",
       " 29,\n",
       " 33,\n",
       " 29,\n",
       " 26,\n",
       " 34,\n",
       " 34,\n",
       " 29,\n",
       " 30,\n",
       " 23,\n",
       " 29,\n",
       " 30,\n",
       " 26,\n",
       " 25,\n",
       " 18,\n",
       " 16,\n",
       " 33,\n",
       " 31,\n",
       " 27,\n",
       " 21,\n",
       " 31,\n",
       " 21,\n",
       " 21,\n",
       " 20,\n",
       " 23,\n",
       " 28,\n",
       " 22,\n",
       " 36,\n",
       " 32,\n",
       " 36,\n",
       " 30,\n",
       " 37,\n",
       " 36,\n",
       " 34,\n",
       " 31,\n",
       " 24,\n",
       " 27,\n",
       " 27,\n",
       " 30,\n",
       " 35,\n",
       " 35,\n",
       " 25]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_atom_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
